{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1+cu117'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.23.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. **Buidling blocks**\n",
    "+ scalar = 0-dimension tensor\n",
    "+ vector = 1-dimension tensor\n",
    "+ **matrix** vs **tensor**:  \n",
    "    **matrix** = 2-dimension tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# scalar is 0-dimension tensor, 1-dimension vector/matrix\n",
    "scalar = torch.tensor(1)\n",
    "print(scalar)\n",
    "print(scalar.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the value inside a 0-dimension (or a scalar)\n",
    "# .item() can only work with scalar\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [1, 2, 3],\n",
       "         [1, 2, 3]],\n",
       "\n",
       "        [[1, 2, 3],\n",
       "         [1, 2, 3],\n",
       "         [1, 2, 0]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# every element of a tensor has to have equal length\n",
    "torch.tensor(\n",
    "    [\n",
    "    [[1,2,3],[1,2,3],[1,2,3]],\n",
    "    [[1,2,3],[1,2,3],[1,2,0]]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_TENSOR.shape = torch.Size([3, 2])\n",
      "\n",
      "np.array(TEST_TENSOR).shape = (3, 2)\n",
      "\n",
      "TEST_TENSOR.ndim = 2\n",
      "\n",
      "np.array(TEST_TENSOR).ndim = 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TEST_TENSOR = torch.tensor([[2,1],[4,2],[1,2]])\n",
    "\n",
    "'''\n",
    "Dimensions in numpy array (or tensors) are number of \n",
    "nested elements, or number of nested sets of values:\n",
    "-> to get the shape of a tensor/array: how the elements are arranged\n",
    "    + np.array.shape == torch.tensor.shape\n",
    "-> to get the dimensions a tensor/array\n",
    "    + np.array.ndim == torch.tensor.ndim\n",
    "'''\n",
    "print(f\"{TEST_TENSOR.shape = }\\n\")\n",
    "print(f\"{np.array(TEST_TENSOR).shape = }\\n\")\n",
    "print(f\"{TEST_TENSOR.ndim = }\\n\")\n",
    "print(f\"{np.array(TEST_TENSOR).ndim = }\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]],\n",
    "                        [[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]]])\n",
    "MATRIX = torch.tensor([[1,2],[4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# TENSOR and MATRIX are often uppercase and using interchagebly\n",
    "# MATRIX is 2 dimensional, -> 2-dimension tensor\n",
    "print(TENSOR.ndim)\n",
    "print(MATRIX.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. **Gain Momentum**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dummy tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dummy tensor\n",
    "# the model/sofware will fill in/update that tensor later\n",
    "RANDOM_TENSORS = torch.rand(size = (3,2,4))\n",
    "ZEROS_TENSORS = torch.zeros(size = (3,2,4))\n",
    "ONES_TENSORS = torch.ones(size = (3,2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.9725, 0.4181, 0.0502, 0.2080],\n",
       "          [0.5194, 0.0999, 0.3147, 0.2346]],\n",
       " \n",
       "         [[0.7656, 0.6727, 0.0484, 0.1756],\n",
       "          [0.1026, 0.4308, 0.8649, 0.1113]],\n",
       " \n",
       "         [[0.9695, 0.3176, 0.1482, 0.7691],\n",
       "          [0.6834, 0.9394, 0.0342, 0.4809]]]),\n",
       " tensor([[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]]),\n",
       " tensor([[[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_TENSORS,ZEROS_TENSORS,ONES_TENSORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Generate range (1-d tensor)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_to_one = torch.arange(0,1,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(type(zero_to_one))\n",
    "print(zero_to_one.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tensors of zeros/ones with the same shape of another tensor\n",
    "zeros_like = torch.ones_like(input=zero_to_one)\n",
    "ones_like = torch.zeros_like(input=zero_to_one)\n",
    "zeros_like,ones_like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Datatypes**\n",
    "+ some are better computed on **CPU**, and others, **GPU**\n",
    "+ default is torch.**float32** (or torch.**float**):\n",
    "    + torch.**float16** (torch.**half**)\n",
    "    + torch.**float64** (torch.**double**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns the number of GPUs available\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "# Default device is cpu\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0])\n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('torch.cuda.HalfTensor', device(type='cuda', index=0))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign a floating float16 tensor to gpu\n",
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=torch.float16,\n",
    "                               device=\"cuda\") \n",
    "\n",
    "float_16_tensor.type(),float_16_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **When ever** there's a problem, it is usually related to one of these three:\n",
    "    + **Where** is my tensor **stored**\n",
    "    + What is the **shape** of my tensor (most of the time)\n",
    "    + What is the **type** of *my tensor*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. **Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 12, 13])\n",
      "tensor([-9, -8, -7])\n",
      "tensor([1, 4, 9])\n",
      "tensor([0.1000, 0.2000, 0.3000])\n"
     ]
    }
   ],
   "source": [
    "vector = torch.tensor([1,2,3])\n",
    "print(vector + 10)\n",
    "print(vector - 10)\n",
    "print(vector * vector)\n",
    "print(vector / 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. **Matrix** multiplication => create **dot product**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_TENSOR_1 = torch.rand(size = (2,3))\n",
    "test_TENSOR_2 = torch.rand(size = (3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1035, 0.9241, 0.7878, 0.6197],\n",
      "        [1.3066, 1.0279, 0.6575, 0.8258]])\n",
      "tensor([[1.1035, 0.9241, 0.7878, 0.6197],\n",
      "        [1.3066, 1.0279, 0.6575, 0.8258]])\n",
      "mat1 and mat2 shapes cannot be multiplied (3x4 and 2x3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# can only be done with the number of rows equal to number of columns\n",
    "print(test_TENSOR_1 @ test_TENSOR_2) # using @ \n",
    "# using torch.matmul()\n",
    "# torch.mm() has the same effect\n",
    "print(torch.matmul(test_TENSOR_1,test_TENSOR_2)) \n",
    "\n",
    "try:\n",
    "    test_TENSOR_2 @ test_TENSOR_1\n",
    "except Exception as e:\n",
    "    print(str(e)+\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. **Element-wise** multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9602, 0.6516, 0.4917],\n",
       "        [0.4499, 3.8784, 0.3187]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    test_TENSOR_1 * test_TENSOR_2\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# multication among individual values of 2 matrix\n",
    "# => 2 matrices have to have to same size \n",
    "\n",
    "test_TENSOR_1 * torch.tensor([[1,2,3],[1,4,1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. **Tensor aggregations** (min, max, mean, median, sum, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1. **Basics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_MATRIX = torch.tensor([\n",
    "                [1,2,1],\n",
    "                [1,54,4],\n",
    "                [1,9,6]\n",
    "                ],dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.7778) tensor(8.7778)\n",
      "tensor(79.) tensor(79.)\n",
      "tensor(54.) tensor(54.)\n",
      "tensor(1.) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(torch.mean(test_MATRIX),test_MATRIX.mean())\n",
    "print(torch.sum(test_MATRIX),test_MATRIX.sum())\n",
    "print(torch.max(test_MATRIX),test_MATRIX.max())\n",
    "print(torch.min(test_MATRIX),test_MATRIX.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2. Find **positional min and max**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [1],\n",
      "        [1]]) tensor([[0, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    test_MATRIX.argmax(dim=1,keepdim=True),\n",
    "    test_MATRIX.argmax(dim=0,keepdim=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_MATRIX[0,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. **Changing the shape of the tensor**\n",
    "+ **Reshapping** - reshape input into a redefined shape (**change memory**)\n",
    "+ **View** - new tensor is **NOT** created => using the **same memory slots** as the input tensor\n",
    "+ **Stacking** - merge multiple tensors (**horizontally** or **vertically**)\n",
    "+ **Squeeze** - removes all 1-d's from a tensor ???\n",
    "+ **Unsqueeze** - add a 1-d to a target tensor\n",
    "+ **Permute** - return a **view** of the input tensor, but **dimensions permuted (swappedd)** in a particular way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. **Reshaping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "         54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
       "         72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "         90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       " torch.Size([100]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0,100,1)\n",
    "x,x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RESHAPE, add an extra dimension\n",
    "x_reshape = x.reshape(1,100)\n",
    "x_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape '[1, 99]' is invalid for input of size 100\n",
      "x_reshape.shape = torch.Size([10, 2, 5])\n",
      "x_reshape.ndim = 3\n"
     ]
    }
   ],
   "source": [
    "# the shape has to fit all the original value\n",
    "try:\n",
    "    x_reshape = x.reshape(1,99)\n",
    "except Exception as e:\n",
    "    print(str(e))\n",
    "\n",
    "# shape of 10,2,5\n",
    "# 3 tensors\n",
    "x_reshape = x.reshape(10,2,5)\n",
    "print(f\"{x_reshape.shape = }\")\n",
    "\n",
    "print(f\"{x_reshape.ndim = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. **View**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_view.shape = torch.Size([2, 2, 25])\n",
      "x_view.ndim = 3\n"
     ]
    }
   ],
   "source": [
    "# just like the reshaping, but there's not memmory wasted\n",
    "x_view = x.view(2,2,25)\n",
    "print(f\"{x_view.shape = }\")\n",
    "print(f\"{x_view.ndim = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 99, 99,  3,  4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing a view with change the input tensor\n",
    "## at the index 0 of first tensor, 0 of second tensor\n",
    "## change the value of the 1 and 2-indexed scalar to 99 and 99\n",
    "x_view[0,0,1:3] = torch.tensor([99,99])\n",
    "\n",
    "# check the input tensor\n",
    "x[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. **Stack**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.stack([x,x],dim=0).shape = torch.Size([2, 100])\n",
      "torch.stack([x,x],dim=1).shape = torch.Size([100, 2])\n"
     ]
    }
   ],
   "source": [
    "# create new dimension\n",
    "# change the shape\n",
    "print(f\"{torch.stack([x,x],dim=0).shape = }\")\n",
    "print(f\"{torch.stack([x,x],dim=1).shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.stack([x_reshape,x_reshape],dim=0).shape = torch.Size([2, 10, 2, 5])\n",
      "torch.stack([x_reshape,x_reshape],dim=1).shape = torch.Size([10, 2, 2, 5])\n",
      "torch.stack([x_reshape,x_reshape],dim=2).shape = torch.Size([10, 2, 2, 5])\n",
      "torch.stack([x_reshape,x_reshape],dim=3).shape = torch.Size([10, 2, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "# the tensor can only be stacked on existing dimension\n",
    "## In this example, x_reshape has 3 dimensions\n",
    "## => can be stacked in 4 different dimension\n",
    "print(f\"{torch.stack([x_reshape,x_reshape],dim=0).shape = }\")\n",
    "print(f\"{torch.stack([x_reshape,x_reshape],dim=1).shape = }\")\n",
    "print(f\"{torch.stack([x_reshape,x_reshape],dim=2).shape = }\")\n",
    "print(f\"{torch.stack([x_reshape,x_reshape],dim=3).shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. **Squeezing** and **Permuting** tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of the tensor: torch.Size([1, 21, 3, 4])\n",
      "Squeeze at the 1st dimension torch.Size([21, 3, 4])\n",
      "Squeeze at the 2nd dimension torch.Size([1, 21, 3, 4])\n",
      "Squeeze at the 3rd dimension torch.Size([1, 21, 3, 4])\n",
      "Squeeze at all dimensions torch.Size([21, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# squeezing, removing 1-d's\n",
    "x_zeros = torch.zeros(size=(1,21,3,4))\n",
    "print(f\"Original shape of the tensor: {x_zeros.shape}\")\n",
    "print(f\"Squeeze at the 1st dimension {x_zeros.squeeze(0).shape}\")\n",
    "print(f\"Squeeze at the 2nd dimension {x_zeros.squeeze(1).shape}\")\n",
    "print(f\"Squeeze at the 3rd dimension {x_zeros.squeeze(2).shape}\")\n",
    "print(f\"Squeeze at all dimensions {x_zeros.squeeze().shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 21, 3, 1, 4])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add dimension, unsqueez()\n",
    "x_zeros.unsqueeze(dim=3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 1, 4, 3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# permute, rearange the dimension\n",
    "# this is also a view\n",
    "x_zeros.permute(1,0,3,2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. **Indexing** (similar to *NumPy*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(0.0,100.,5).reshape(5,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5., 25., 45., 65., 85.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  5],\n",
       "         [10, 15]],\n",
       "\n",
       "        [[20, 25],\n",
       "         [30, 35]],\n",
       "\n",
       "        [[40, 45],\n",
       "         [50, 55]],\n",
       "\n",
       "        [[60, 65],\n",
       "         [70, 75]],\n",
       "\n",
       "        [[80, 85],\n",
       "         [90, 95]]], dtype=torch.int8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.type(torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('data_science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a10e4b5ad14839566a2f735df5e9b3727c3adb97c6db97ba3b9982fff39dfe07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
